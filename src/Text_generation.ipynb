{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "yabEj0fem-v7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BuyUdbqOfO9",
        "outputId": "f995d166-7cdd-42a2-e59f-e4111c44852c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'archive (4).zip'   sample_data   scraped.zip\n"
          ]
        }
      ],
      "source": [
        "!ls /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKQersf0Q2FB",
        "outputId": "62390781-22bb-4c00-e72d-ff251b48f800"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " '.ipynb_checkpoints',\n",
              " 'archive (4).zip',\n",
              " 'scraped.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!file scraped.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koNBPPs5RlqO",
        "outputId": "1ab5323d-6c6f-4703-a3ff-248baa7fc731"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scraped.zip: Zip archive data, at least v4.5 to extract, compression method=deflate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y p7zip-full\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt5O1TNdR4Dd",
        "outputId": "c3faa85b-d390-4833-ddef-26f36dda25d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (65.9.86.118)] [Conn\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [2 InRelease 60.5 kB/128 kB 47%] [3 InRelease 14.2 kB/129 kB 11%] [Connected\r                                                                               \rGet:4 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [2 InRelease 80.8 kB/128 kB 63%] [3 InRelease 14.2 kB/129 kB 11%] [Waiting f\r0% [2 InRelease 80.8 kB/128 kB 63%] [3 InRelease 14.2 kB/129 kB 11%] [Waiting f\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [2 InRelease 98.2 kB/128 kB 77%] [3 InRelease 14.2 kB/129 kB 11%] [Waiting f\r0% [2 InRelease 102 kB/128 kB 80%] [3 InRelease 14.2 kB/129 kB 11%] [Waiting fo\r                                                                               \rGet:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [2 InRelease 110 kB/128 kB 86%] [3 InRelease 14.2 kB/129 kB 11%] [6 InReleas\r0% [2 InRelease 110 kB/128 kB 86%] [3 InRelease 14.2 kB/129 kB 11%] [Connecting\r0% [3 InRelease 22.9 kB/129 kB 18%] [Connecting to r2u.stat.illinois.edu (192.1\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r0% [7 InRelease 15.6 kB/127 kB 12%] [3 InRelease 37.3 kB/129 kB 29%] [Connectin\r0% [3 InRelease 43.1 kB/129 kB 33%] [Connected to r2u.stat.illinois.edu (192.17\r                                                                               \rHit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [3 InRelease 101 kB/129 kB 78%] [Connected to r2u.stat.illinois.edu (192.17.\r                                                                               \r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                              \rHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://cli.github.com/packages stable/main amd64 Packages [345 B]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,205 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,965 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [36.9 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,851 kB]\n",
            "Get:23 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,546 kB]\n",
            "Fetched 38.2 MB in 3s (12.0 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!7z x scraped.zip -o/content/dataset_raw\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gieGppGmSAg1",
        "outputId": "e6d6a6ac-86e7-45aa-df23-f7076c41cba0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 106954752 bytes (102 MiB)\n",
            "\n",
            "Extracting archive: scraped.zip\n",
            "\n",
            "ERRORS:\n",
            "Unexpected end of archive\n",
            "\n",
            "--\n",
            "Path = scraped.zip\n",
            "Type = zip\n",
            "ERRORS:\n",
            "Unexpected end of archive\n",
            "Physical Size = 261791118\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  3% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bERROR: Data Error : scraped_data.txt\n",
            "100% - scraped_data.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Sub items Errors: 1\n",
            "\n",
            "Archives with Errors: 1\n",
            "\n",
            "Open Errors: 1\n",
            "\n",
            "Sub items Errors: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\"/content/dataset_raw\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoX07pThSO_e",
        "outputId": "5b4ad966-7ad1-461e-e68c-7dcdfc3bd25f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scraped_data.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/dataset_raw/scraped_data.txt\"  # adjust name\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qnRYIl2SUEV",
        "outputId": "8cdd7dc0-e624-4680-d384-e343a89955de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Wikipedia, the free encyclopedia\n",
            "\n",
            "\n",
            "\n",
            "Content: Wikipedia, the free encyclopedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Search Search Create account Log in Personal tools Create account Log in Pages for logged out editors learn more Contributions Talk Main Page Main Page Talk English Read View source View history Tools Tools move to sidebar hide Actions Read View source View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikimedia Foundation MediaWiki Meta-Wiki Wikimedia Outreach Multilingual Wikisource Wikispecies Wikibooks Wikidata Wikifunctions Wikimania Wikinews Wikiquote Wikisource Wikiversity Wikivoyage Wiktionary From Wikipedia, the free encyclopedia Welcome to Wikipedia , the free encyclopedia that anyone can edit . 6,733,856 articles in English From today's featured article Howard Florey (1898–1968) was an Australian pharmacologist and pathologist who shared the Nobel Prize in Physiology or Medicine in 1945 with Ernst Chain and Alexander Fleming for his role in the development of the antibiotic penicillin . While Fleming received most of the credit for the drug's discovery, it was Florey and his team at the University of Oxford in England who developed techniques for growing, purifying and manufacturing it, tested it on animals and carried out the first clinical trials. Later trials in Britain, the United States and North Africa were highly successful. In addition to his work on penicillin, Florey studied other antibiotics , including lysozyme and the cephalosporins , and researched contraception . He was elected President of the Royal Society in 1960, became the provost of The Queen's College at Oxford in 1962, and served as the chancellor of the Australian National University from 1965 until his death. Florey's discoveries are estimated to have saved more than 80 million lives. ( Full article... ) Recently featured: South Asian river dolphin The Kinks' 1965 US tour Second Battle of Independence Archive By email More featured articles About Did you know ... The vehicles used on the Lingang DRT ... that according to one traveller, the rapid transit system Lingang DRT (pictured) took an hour to travel what a car could do in 20 minutes and a bus in 40? ... that Shukriyya Akhundzada learned of her husband's death 15 years after it occurred? ... that New Zealand's election mascot Orange Guy has a pet dog named Pup? ... that the early drafts of Appalachian Spring contained a Native American girl to act as an invisible theatrical device, but it was cut in the final production? ... that Steem peanut butter contained as much caffeine per serving as two cups of coffee? ... that in a copyright infringement case over a coffee-table history of the Grateful Dead , the Second Circuit held that a reuser can still claim fair use despite negotiating with the rights holder? ... that an Alabama radio station was described by its program director as a \"no-format mess\"? ... that officials said this year's Louisiana wildfire season includes the largest wildfire in the state's history? Archive Start a new article Nominate an article In the news Daniel Noboa Daniel Noboa (pictured) is elected President of Ecuador . Parties opposing the incumbent Law and Justice party win a combined majority of seats in the Polish general election . The National Party , led by Christopher Luxon , wins the most seats in the New Zealand general election . Australian voters reject altering the Constitution to establish an Indigenous Voice to Parliament . Ongoing : Israel–Hamas war Russian invasion of Ukraine timeline Recent deaths : Martti Ahtisaari Tony Husband Carmen Petra Basacopol Summa Navaratnam Geri M. Joseph Hatto Beyerle Nominate an article On this day October 25 Terence MacSwiney 1415 – Hundred Years' War : The army of Henry V of England , consisting mostly of archers, unexpectedly defeated the numerically superior French cavalry at the Battle of Agincourt on Saint Crispin's Day . 1760 – George III became King of Great Britain and Ireland, succeeding his grandfather George II . 1920 – Irish playwright and politician Terence MacSwiney (pictured) died after a hunger strike in Brixton Prison , bringing the Irish struggle for independence to international attention. 1927 – The Italian cruise liner SS Principessa Mafalda sank when a propeller shaft broke and fractured the hull, resulting in 314 deaths. 1980 – Proceedings on the Hague Abduction Convention , a multilateral treaty providing an expeditious method to return a child taken from one member nation to another, concluded at The Hague . Magnus the Good ( d. 1047) Johann Strauss II ( b. 1825) Larry Itliong ( b. 1913) Nancy Cartwright ( b. 1957) More anniversaries: October 24 October 25 October 26 Archive By email List of days of the year Today's featured picture The Neue Nationalgalerie is a museum for modern art in Berlin, Germany, with its main focus on the 20th century. It is part of the National Gallery of the Berlin State Museums . The museum building and its sculpture gardens were designed by Ludwig Mies van der Rohe and opened in 1968, with a modernist design and constructed largely from steel and glass. Neue Nationalgalerie serves as a repository for a notable collection of 20th-century European art. Its holdings include masterpieces by prominent figures such as Pablo Picasso , Wassily Kandinsky , Ernst Ludwig Kirchner , and Joan Miró . The gallery closed in 2015 for renovation works, and reopened in August 2021 with an exhibition of works by American sculptor Alexander Calder . This photograph is a view of the western and southern façades of the building, with Calder's sculpture Têtes et Queue in the foreground. Photograph credit: Alexander Savin Recently featured: Arothron stellatus Blue Horse I Heliconius charithonia Archive More featured pictures Other areas of Wikipedia Community portal – The central hub for editors, with resources, links, tasks, and announcements. Village pump – Forum for discussions about Wikipedia itself, including policies and technical issues. Site news – Sources of news about Wikipedia and the broader Wikimedia movement. Teahouse – Ask basic questions about using or editing Wikipedia. Help desk – Ask questions about using or editing Wikipedia. Reference desk – Ask research questions about encyclopedic topics. Content portals – A unique way to navigate the encyclopedia. Wikipedia's sister projects Wikipedia is written by volunteer editors and hosted by the Wikimedia Foundation , a non-profit organization that also hosts a range of other volunteer projects : Commons Free media repository MediaWiki Wiki software development Meta-Wiki Wikimedia project coordination Wikibooks Free textbooks and manuals Wikidata Free knowledge base Wikinews Free-content news Wikiquote Collection of quotations Wikisource Free-content library Wikispecies Directory of species Wikiversity Free learning tools Wikivoyage Free travel guide Wiktionary Dictionary and thesaurus Wikipedia languages This Wikipedia is written in English . Many other Wikipedias are available ; some of the largest are listed below. 1,000,000+ articles العربية Deutsch Español Français Italiano Nederlands 日本語 Polski Português Русский Svenska Українська Tiếng Việt 中文 250,000+ articles Bahasa Indonesia Bahasa Melayu Bân-lâm-gú Български Català Čeština Dansk Esperanto Euskara فارسی ‎ עברית Հայերեն 한국어 Magyar Norsk bokmål Română Srpski Srpskohrvatski Suomi Türkçe 50,000+ articles Asturianu বাংলা Bosanski کوردی Eesti Ελληνικά Simple English Frysk Gaeilge Galego Hrvatski ქართული Latviešu Lietuvių മലയാളം Македонски Norsk nynorsk ਪੰਜਾਬੀ Shqip Slovenčina Slovenščina ไทย తెలుగు Oʻzbekcha / ўзбекча Retrieved from \" https://en.wikipedia.org/w/index.php?title=Main_Page&oldid=1114291180 \" 47 languages العربية বাংলা Български Bosanski Català Čeština Dansk Deutsch Eesti Ελληνικά Español Esperanto Euskara فارسی Français Galego 한국어 Hrvatski Bahasa Indonesia Italiano עברית ქართული Latviešu Lietuvių Magyar Македонски Bahasa Melayu Nederlands 日本語 Norsk bokmål Norsk nynorsk Polski Português Română Русский Simple English Slovenčina Slovenščina Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska ไทย Türkçe Українська Tiếng Việt 中文 This page was last edited on 5 October 2022, at 19:27 (UTC) . Text is available under the Creative Commons Attribution-ShareAlike License 4.0 ;\n",
            "\n",
            "additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc. , a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Toggle limited content width\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "base_path = \"/content/text_generation_rnn\"\n",
        "os.makedirs(base_path + \"/dataset/raw\", exist_ok=True)\n",
        "\n",
        "shutil.move(\n",
        "    \"/content/dataset_raw/scraped_data.txt\",\n",
        "    base_path + \"/dataset/raw/wiki_corpus.txt\"\n",
        ")\n",
        "\n",
        "print(\"Dataset ready ✔\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00IcaTe0ScyK",
        "outputId": "6bb3a446-1fd5-40bd-af89-79f8d8973724"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing"
      ],
      "metadata": {
        "id": "oDK-dIianJ6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import itertools\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "RAW_TEXT_PATH = \"/content/text_generation_rnn/dataset/raw/wiki_corpus.txt\"\n",
        "\n",
        "MAX_LINES = 900_000   # SAFE LIMIT (~5–10MB text)\n",
        "\n",
        "lines = []\n",
        "\n",
        "with open(RAW_TEXT_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in itertools.islice(f, MAX_LINES):\n",
        "        lines.append(line)\n",
        "\n",
        "print(\"Lines loaded:\", len(lines))\n",
        "\n",
        "text = \" \".join(lines)\n",
        "\n",
        "# Clean\n",
        "text = text.lower()\n",
        "text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "print(\"Text length:\", len(text))\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token=\"<unk>\")\n",
        "tokenizer.fit_on_texts([text])\n",
        "\n",
        "print(\"Vocabulary size:\", min(len(tokenizer.word_index), 20000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh_2wzFQSeKO",
        "outputId": "eec2533d-ffb0-491d-e30c-a65cb32c48cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines loaded: 312932\n",
            "Text length: 287222746\n",
            "Vocabulary size: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "SEQ_LEN = 10\n",
        "MAX_SAMPLES = 300_000   # HARD LIMIT (do not increase now)\n",
        "\n",
        "# Convert text → word indices\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "print(\"Total tokens:\", len(tokens))\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(SEQ_LEN, min(len(tokens), MAX_SAMPLES)):\n",
        "    X.append(tokens[i-SEQ_LEN:i])\n",
        "    y.append(tokens[i])\n",
        "\n",
        "X = np.array(X, dtype=np.int32)\n",
        "y = np.array(y, dtype=np.int32)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aKMG4qpcFvf",
        "outputId": "55f96aaf-435a-4856-ad86-4d518365af27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 45494891\n",
            "X shape: (299990, 10)\n",
            "y shape: (299990,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "PROCESSED_PATH = \"/content/text_generation_rnn/dataset/processed\"\n",
        "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
        "\n",
        "np.save(PROCESSED_PATH + \"/input_sequences.npy\", X)\n",
        "np.save(PROCESSED_PATH + \"/output_words.npy\", y)\n",
        "\n",
        "with open(PROCESSED_PATH + \"/word2idx.json\", \"w\") as f:\n",
        "    json.dump(tokenizer.word_index, f)\n",
        "\n",
        "print(\"✅ Dataset saved successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-TAr5CccLyM",
        "outputId": "d39c732b-94cb-4ef7-8db1-edc9f2de6a82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Buildig model: LSTM"
      ],
      "metadata": {
        "id": "CK962ExRnTUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Paths\n",
        "DATA_PATH = \"/content/text_generation_rnn/dataset/processed\"\n",
        "MODEL_PATH = \"/content/text_generation_rnn/models/lstm_text_generator.h5\"\n",
        "\n",
        "# Load dataset\n",
        "X = np.load(DATA_PATH + \"/input_sequences.npy\")\n",
        "y = np.load(DATA_PATH + \"/output_words.npy\")\n",
        "\n",
        "with open(DATA_PATH + \"/word2idx.json\", \"r\") as f:\n",
        "    word2idx = json.load(f)\n",
        "\n",
        "vocab_size = min(len(word2idx) + 1, 20000)\n",
        "seq_len = X.shape[1]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "# -----------------------------\n",
        "# Build Advanced LSTM Model\n",
        "# -----------------------------\n",
        "model = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=128,\n",
        "        input_length=seq_len\n",
        "    ),\n",
        "\n",
        "    LSTM(256, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    LSTM(256),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]  # accuracy is logged but NOT trusted\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "CbnsEWVKc3ME",
        "outputId": "35ab2324-17b3-4bdf-b3a1-26581be9fd08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (299990, 10)\n",
            "y shape: (299990,)\n",
            "Vocab size: 20000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        MODEL_PATH,\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    batch_size=128,\n",
        "    epochs=20,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwAFIlA-c9Pu",
        "outputId": "82b34e60-ef88-49dc-ca36-7ff1f71f6b7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2109/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1050 - loss: 6.9302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 18ms/step - accuracy: 0.1051 - loss: 6.9298 - val_accuracy: 0.2331 - val_loss: 6.8758\n",
            "Epoch 2/20\n",
            "\u001b[1m2107/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1894 - loss: 5.6865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.1894 - loss: 5.6863 - val_accuracy: 0.2603 - val_loss: 6.7860\n",
            "Epoch 3/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2340 - loss: 5.1714 - val_accuracy: 0.2651 - val_loss: 6.9494\n",
            "Epoch 4/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2561 - loss: 4.8293 - val_accuracy: 0.2696 - val_loss: 7.1402\n",
            "Epoch 5/20\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.2736 - loss: 4.5588 - val_accuracy: 0.2662 - val_loss: 7.3859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing GRU model"
      ],
      "metadata": {
        "id": "1HPKEY3enXeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"deep learning is a field that\", temperature=0.7, top_k=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSaZhEzLfsdW",
        "outputId": "de254262-466a-49bf-b42e-75894384b96c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep learning is a field that and to the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load dataset\n",
        "DATA_PATH = \"/content/text_generation_rnn/dataset/processed\"\n",
        "\n",
        "X = np.load(DATA_PATH + \"/input_sequences.npy\")\n",
        "y = np.load(DATA_PATH + \"/output_words.npy\")\n",
        "\n",
        "with open(DATA_PATH + \"/word2idx.json\", \"r\") as f:\n",
        "    word2idx = json.load(f)\n",
        "\n",
        "vocab_size = 20000\n",
        "seq_len = X.shape[1]\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# GRU MODEL (BEST FOR YOU)\n",
        "# ---------------------------\n",
        "model = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=128,\n",
        "        input_shape=(seq_len,)\n",
        "    ),\n",
        "\n",
        "    GRU(256, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    GRU(256),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "0-oj62l4gNKV",
        "outputId": "0d2c5352-ee23-4f78-c33b-9bc134fad2e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (299990, 10)\n",
            "y: (299990,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m296,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m394,752\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │     \u001b[38;5;34m5,140,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,456,992\u001b[0m (32.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,456,992</span> (32.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,456,992\u001b[0m (32.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,456,992</span> (32.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    batch_size=128,\n",
        "    epochs=8,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[\n",
        "        EarlyStopping(\n",
        "            monitor=\"val_loss\",\n",
        "            patience=2,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D63IZCiZgO6F",
        "outputId": "208e09af-161e-4c21-9ac4-68e8596f3e54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.1145 - loss: 6.8457 - val_accuracy: 0.2507 - val_loss: 6.8125\n",
            "Epoch 2/8\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18ms/step - accuracy: 0.2120 - loss: 5.5506 - val_accuracy: 0.2602 - val_loss: 6.9089\n",
            "Epoch 3/8\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18ms/step - accuracy: 0.2476 - loss: 5.0988 - val_accuracy: 0.2637 - val_loss: 7.0430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(\n",
        "    seed_text,\n",
        "    num_words=30,\n",
        "    temperature=0.7,\n",
        "    top_k=10,\n",
        "    repetition_penalty=1.2\n",
        "):\n",
        "    result = seed_text.lower().split()\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        encoded = [word2idx.get(w, word2idx[\"<unk>\"]) for w in result[-SEQ_LEN:]]\n",
        "        padded = pad_sequences([encoded], maxlen=SEQ_LEN)\n",
        "\n",
        "        preds = model.predict(padded, verbose=0)[0]\n",
        "\n",
        "        # 🔥 repetition penalty\n",
        "        for w in set(result[-5:]):\n",
        "            if w in word2idx:\n",
        "                preds[word2idx[w]] /= repetition_penalty\n",
        "\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        probs = np.exp(preds) / np.sum(np.exp(preds))\n",
        "\n",
        "        top_indices = np.argsort(probs)[-top_k:]\n",
        "        top_probs = probs[top_indices]\n",
        "        top_probs /= np.sum(top_probs)\n",
        "\n",
        "        next_idx = np.random.choice(top_indices, p=top_probs)\n",
        "        next_word = idx2word.get(next_idx, \"\")\n",
        "\n",
        "        if next_word in [\"<unk>\", result[-1]]:\n",
        "            continue\n",
        "\n",
        "        result.append(next_word)\n",
        "\n",
        "    return \" \".join(result)\n"
      ],
      "metadata": {
        "id": "5wIR0OCEkGcP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    generate_text(\n",
        "        \"deep learning is a field of artificial intelligence that\",\n",
        "        temperature=0.6,\n",
        "        top_k=8,\n",
        "        repetition_penalty=1.3\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlscLlOgyfi",
        "outputId": "bd57dc46-b191-4a63-bd99-0f38703b7f84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep learning is a field of artificial intelligence that a nobel prize is to a university of the national university of the prize of the university of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying to build transformer - mini gpt"
      ],
      "metadata": {
        "id": "6KW-l06-nuiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA\n",
        "# =========================\n",
        "DATA_PATH = \"/content/text_generation_rnn/dataset/processed\"\n",
        "\n",
        "X = np.load(DATA_PATH + \"/input_sequences.npy\")\n",
        "y = np.load(DATA_PATH + \"/output_words.npy\")\n",
        "\n",
        "with open(DATA_PATH + \"/word2idx.json\", \"r\") as f:\n",
        "    word2idx = json.load(f)\n",
        "\n",
        "idx2word = {v: k for k, v in word2idx.items()}\n",
        "\n",
        "VOCAB_SIZE = 20000\n",
        "SEQ_LEN = X.shape[1]\n",
        "\n",
        "print(\"X:\", X.shape, \"y:\", y.shape)\n",
        "\n",
        "# =========================\n",
        "# TRANSFORMER BLOCK\n",
        "# =========================\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=embed_dim\n",
        "        )\n",
        "        self.ffn = models.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attn_output = self.att(\n",
        "            inputs, inputs,\n",
        "            use_causal_mask=True\n",
        "        )\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# =========================\n",
        "# TOKEN + POSITION EMBEDDING\n",
        "# =========================\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_emb = layers.Embedding(maxlen, embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "# =========================\n",
        "# MINI GPT MODEL\n",
        "# =========================\n",
        "EMBED_DIM = 128\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 256\n",
        "\n",
        "inputs = layers.Input(shape=(SEQ_LEN,))\n",
        "embedding_layer = TokenAndPositionEmbedding(SEQ_LEN, VOCAB_SIZE, EMBED_DIM)\n",
        "x = embedding_layer(inputs)\n",
        "\n",
        "x = TransformerBlock(EMBED_DIM, NUM_HEADS, FF_DIM)(x)\n",
        "x = TransformerBlock(EMBED_DIM, NUM_HEADS, FF_DIM)(x)\n",
        "\n",
        "x = layers.Dense(EMBED_DIM, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x[:, -1, :])\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "lkxnMy-5l6la",
        "outputId": "3fbf7777-1c76-453a-ec02-7460a6ed81a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (299990, 10) y: (299990,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ token_and_position_embedding_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m2,561,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m330,240\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m330,240\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │     \u001b[38;5;34m2,580,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ token_and_position_embedding_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,561,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,818,272\u001b[0m (22.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,818,272</span> (22.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,818,272\u001b[0m (22.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,818,272</span> (22.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    validation_split=0.1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQpD4gnwmOyb",
        "outputId": "780fd68b-8568-4e45-e865-4c06bea6b6a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.1372 - loss: 6.7496 - val_accuracy: 0.2536 - val_loss: 6.7952\n",
            "Epoch 2/5\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.2560 - loss: 5.1418 - val_accuracy: 0.2750 - val_loss: 6.8031\n",
            "Epoch 3/5\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3009 - loss: 4.5089 - val_accuracy: 0.2714 - val_loss: 7.1445\n",
            "Epoch 4/5\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3348 - loss: 4.0212 - val_accuracy: 0.2647 - val_loss: 7.7825\n",
            "Epoch 5/5\n",
            "\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.3651 - loss: 3.6163 - val_accuracy: 0.2653 - val_loss: 8.4094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final testing"
      ],
      "metadata": {
        "id": "gC4tAImZn5Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "def generate_text_transformer(\n",
        "    seed_text,\n",
        "    num_words=30,\n",
        "    temperature=0.8,\n",
        "    top_k=10\n",
        "):\n",
        "    result = seed_text.lower().split()\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        encoded = [word2idx.get(w, word2idx[\"<unk>\"]) for w in result[-SEQ_LEN:]]\n",
        "        padded = pad_sequences([encoded], maxlen=SEQ_LEN)\n",
        "\n",
        "        preds = model.predict(padded, verbose=0)[0]\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        probs = np.exp(preds) / np.sum(np.exp(preds))\n",
        "\n",
        "        top_indices = np.argsort(probs)[-top_k:]\n",
        "        top_probs = probs[top_indices]\n",
        "        top_probs /= np.sum(top_probs)\n",
        "\n",
        "        next_idx = np.random.choice(top_indices, p=top_probs)\n",
        "        next_word = idx2word.get(next_idx, \"\")\n",
        "\n",
        "        if next_word == \"<unk>\":\n",
        "            continue\n",
        "\n",
        "        result.append(next_word)\n",
        "\n",
        "    return \" \".join(result)\n",
        "\n",
        "print(\n",
        "    generate_text_transformer(\n",
        "        \"deep learning is a field of artificial intelligence that\",\n",
        "        temperature=0.7,\n",
        "        top_k=10\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_MVaegcmyj6",
        "outputId": "576dc44a-90d0-4e0c-937f-bc987533fab3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep learning is a field of artificial intelligence that are also used to have been blocked for other editors and the most common encyclopedia in english is an official language for the encyclopedia of the united nations\n"
          ]
        }
      ]
    }
  ]
}